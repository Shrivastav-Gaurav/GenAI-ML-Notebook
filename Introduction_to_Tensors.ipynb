{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shrivastav-Gaurav/GenAI-ML-Notebook/blob/main/Introduction_to_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is a Tensor?\n",
        "\n"
      ],
      "metadata": {
        "id": "uBnPB8kW-Uj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tensor is a generalization of vectors and matrices to potentially higher dimensions, see the Table below. Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes. Each element in the Tensor has the same data type, and the data type is always known. Simply, tensor, in relation to machine learning, is a generalization of scalars, vectors and, matrices.\n",
        "<br><br>\n",
        "<center>\n",
        "<img src= \"https://cdn.iisc.talentsprint.com/AIandMLOps/Images/Intro_tensor.png\" width=700px/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "WnbTBBcRXUlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Library"
      ],
      "metadata": {
        "id": "Cah46EWcFKKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJc4WmIg6oOl",
        "outputId": "bfb16e5d-89b4-4bdf-f7d0-aef17dec93b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creation"
      ],
      "metadata": {
        "id": "66EOtAm9kxLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "YtO3FjmblI36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Direct Creation"
      ],
      "metadata": {
        "id": "hQvDNSdZlAZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8N3f1rrk1_P",
        "outputId": "9541c457-77c7-4e6a-85d4-1184a42dfdb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using `torch.zeros()`"
      ],
      "metadata": {
        "id": "rk0K56pHlPgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_zeros = torch.zeros(3)\n",
        "print(tensor_zeros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LduufMB1k14K",
        "outputId": "6c374f36-0240-4c7f-c764-a67477f2c619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using `torch.ones()`"
      ],
      "metadata": {
        "id": "c3SyAGF0leyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_ones = torch.ones(2, 3)\n",
        "print(tensor_ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7wGPkmzk1ik",
        "outputId": "d75ac64c-3cb8-4347-a543-14319ad21b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using `torch.empty()`"
      ],
      "metadata": {
        "id": "5fZmfKMClsFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_empty = torch.empty(2, 3)\n",
        "print(tensor_empty)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9pYXiZtlwf8",
        "outputId": "999f4e13-1914-4abc-85af-87d0f568cc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-7.2012e+29,  4.5827e-41,  6.2425e+01],\n",
            "        [ 0.0000e+00,  4.4842e-44,  0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Random Initialization"
      ],
      "metadata": {
        "id": "sMf4-KWVmXlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using `torch.randn()`"
      ],
      "metadata": {
        "id": "CFgcE-IQmIP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_norm_distribution = torch.randn(4, 4, 4)\n",
        "print(tensor_norm_distribution)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIvNg2M-l5b1",
        "outputId": "a149fb65-7f8e-4878-b12b-5e43e0f01e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.7516,  0.1403, -0.4128,  1.2203],\n",
            "         [-0.8997,  3.2778, -1.6432, -0.7858],\n",
            "         [ 1.3337,  1.0487,  0.3911,  1.2901],\n",
            "         [-0.4301, -0.1966, -2.4229,  0.2107]],\n",
            "\n",
            "        [[ 2.1888,  0.4934, -1.1037, -0.3060],\n",
            "         [ 0.1497,  0.3080,  1.0626, -1.2945],\n",
            "         [ 0.2286,  0.1839,  0.5812, -0.7024],\n",
            "         [-0.3857,  0.4114,  0.4473, -0.7705]],\n",
            "\n",
            "        [[ 0.6688, -2.2977, -0.7570,  0.2519],\n",
            "         [-1.3559,  0.1091,  0.2178, -0.2534],\n",
            "         [-0.9192,  1.1407, -0.1968,  0.8856],\n",
            "         [-0.2057,  0.0892,  0.8038, -1.3935]],\n",
            "\n",
            "        [[ 0.6986, -0.9948, -1.1566, -0.4969],\n",
            "         [-0.5618,  1.2492,  0.5253, -1.1294],\n",
            "         [-0.9022,  1.5705, -0.9793, -0.6969],\n",
            "         [ 1.1388, -0.1342, -0.1914,  0.4428]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using `torch.rand()`"
      ],
      "metadata": {
        "id": "a7TtyllTmLac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_uniform_distribution = torch.rand(4, 4)\n",
        "print(tensor_uniform_distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bntn8yY-mAVw",
        "outputId": "2a9642a5-9c11-47ac-91e5-9e804b7f3658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9987, 0.1424, 0.2751, 0.9243],\n",
            "        [0.3145, 0.0495, 0.8667, 0.6560],\n",
            "        [0.3834, 0.1183, 0.8890, 0.8559],\n",
            "        [0.7170, 0.4941, 0.3480, 0.1848]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Specific initialization:"
      ],
      "metadata": {
        "id": "lxDnlSQOmpH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using `torch.arange()`"
      ],
      "metadata": {
        "id": "HylWq0B5m1Or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_arange = torch.arange(0, 10, 2)\n",
        "print(tensor_arange)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONp_GZTHnM-i",
        "outputId": "4bac35c5-9ddf-4cab-940e-bd86c6486437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 2, 4, 6, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using `torch.linspace()`"
      ],
      "metadata": {
        "id": "43ps7X3SnEd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_linspace = torch.linspace(0, 1, 5)\n",
        "print(tensor_linspace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ceA79s2nUNn",
        "outputId": "d3d631a9-2144-4f98-8cf7-afe3186ddb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Using `torch.eye()`"
      ],
      "metadata": {
        "id": "1nom5LGqnIhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_eye = torch.eye(3)\n",
        "print(tensor_eye)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvIvizalnhrn",
        "outputId": "fe0e2615-c6fa-4d0a-85eb-c17f9448224c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Create a 3-dimensional tensor with random values from a uniform distribution\n",
        "random_tensor = torch.rand(2, 3, 4)\n",
        "print(random_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APr5Upbcgoqg",
        "outputId": "baa0ad47-ddb7-4db5-b926-bb72d093145b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.2660, 0.8240, 0.8665, 0.2096],\n",
            "         [0.4942, 0.6521, 0.7722, 0.8110],\n",
            "         [0.0438, 0.2807, 0.4389, 0.8550]],\n",
            "\n",
            "        [[0.6957, 0.5408, 0.4197, 0.2850],\n",
            "         [0.3908, 0.4801, 0.9678, 0.7021],\n",
            "         [0.3388, 0.2887, 0.9778, 0.3098]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Other methods"
      ],
      "metadata": {
        "id": "H13aaNKlo2Ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using `torch.from_numpy()`"
      ],
      "metadata": {
        "id": "GxpX-F-ro7Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np_array = np.array([1, 2, 3])\n",
        "tensor_from_np = torch.from_numpy(np_array)\n",
        "print(tensor_from_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F8OQxXEo-Np",
        "outputId": "cc606653-5c37-44cb-c91b-10d1c167f732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using `torch.load()`"
      ],
      "metadata": {
        "id": "3uHTDUoqpIS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.randn(2, 3)\n",
        "torch.save(tensor, 'tensor.pt')"
      ],
      "metadata": {
        "id": "XFiOC2RIpKWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weights_only: Indicates whether unpickler should be restricted to loading only tensors, primitive types, dictionaries\n",
        "tensor_loaded = torch.load('tensor.pt', weights_only=False) # fixes future warning\n",
        "print(tensor_loaded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXDAB6R9qALt",
        "outputId": "2e7d84da-2e27-4911-b618-90bdc96a732a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5212, -1.1785,  1.3157],\n",
            "        [-1.1839, -1.9914, -0.2608]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Mathematical Operations on Tensors\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BNm9-Gg_tgHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "💥 Addition: Adds corresponding elements of tensors together, allowing for combining information or increasing values.\n",
        "\n",
        "💥 Subtraction: Subtracts corresponding elements of tensors, useful for computing differences or detecting changes.\n",
        "\n",
        "💥 Multiplication: Performs element-wise multiplication of tensors, enabling scaling or emphasizing certain features.\n",
        "To perform matrix like multiplication of tensors: torch.matmul(tensor1, tensor2)\n",
        "\n",
        "💥 Division: Divides corresponding elements of tensors, useful for normalization or finding relative proportions."
      ],
      "metadata": {
        "id": "FnWO5BDFF0U-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Create a base tensor\n",
        "base_tensor = torch.tensor ([[1, 2], [3,4]])\n",
        "# Create another tensor\n",
        "second_tensor = torch.tensor ([[2, 2], [1,1]])\n",
        "# Addition\n",
        "addition_tensor = base_tensor + second_tensor\n",
        "print(\"Addition: \\\\n\", addition_tensor)\n",
        "# Subtraction\n",
        "subtraction_tensor = base_tensor - second_tensor\n",
        "print(\"Subtraction: \\\\n\", subtraction_tensor)\n",
        "# Multiplication\n",
        "multiplication_tensor = base_tensor * second_tensor\n",
        "print(\"Multiplication: \\\\n\", multiplication_tensor)\n",
        "# Division\n",
        "division_tensor = base_tensor / second_tensor\n",
        "print(\"Division: In\", division_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHUisZwctrd7",
        "outputId": "c2734245-459e-4f3d-dd63-58b421306ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition: \\n tensor([[3, 4],\n",
            "        [4, 5]])\n",
            "Subtraction: \\n tensor([[-1,  0],\n",
            "        [ 2,  3]])\n",
            "Multiplication: \\n tensor([[2, 4],\n",
            "        [3, 4]])\n",
            "Division: In tensor([[0.5000, 1.0000],\n",
            "        [3.0000, 4.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor indexing and slicing  \n"
      ],
      "metadata": {
        "id": "ymAddp0-t_72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`::` in tensor slicing in PyTorch (or NumPy) is used to specify a step size.\n",
        "\n",
        "When you use `::` within square brackets when indexing a tensor, you're essentially telling Python to select elements from the tensor at regular intervals.\n",
        "\n",
        "### **Breakdown:**\n",
        "\n",
        "1. First `:` Indicates the starting index (usually 0 if omitted).\n",
        "1. Second `:` Indicates the ending index (usually the end of the tensor if omitted).\n",
        "1. `:` Specifies the step size."
      ],
      "metadata": {
        "id": "FFdAr-97X4KT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-D Tensor Example"
      ],
      "metadata": {
        "id": "8kkUZI4KLxCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
        "\n",
        "# Extract every other element\n",
        "subtensor = tensor[::2]  # Output: tensor([1, 3, 5])\n",
        "\n",
        "# Extract elements starting from the 2nd index, every 3rd element\n",
        "subtensor = tensor[1::3]  # Output: tensor([2, 5])"
      ],
      "metadata": {
        "id": "VKgbvjrpKnOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Dimension Example"
      ],
      "metadata": {
        "id": "bTJnxa4OL0NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Create a 3-D tensor with size (2, 3, 3)\n",
        "tensor = torch.tensor ([\n",
        "\t[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
        "\t[[10, 11, 12], [13, 14, 15],[16, 17,18]]\n",
        "])\n",
        "print (\"Original Tensor:\")\n",
        "print (tensor, end='\\n\\n')\n",
        "print(\"Tensor Shape:\", tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KWgPlimuFxK",
        "outputId": "b7a45eaf-607d-435f-8eaa-63de2d3f93fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            "tensor([[[ 1,  2,  3],\n",
            "         [ 4,  5,  6],\n",
            "         [ 7,  8,  9]],\n",
            "\n",
            "        [[10, 11, 12],\n",
            "         [13, 14, 15],\n",
            "         [16, 17, 18]]])\n",
            "\n",
            "Tensor Shape: torch.Size([2, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the shape of a tensor is essential for working with PyTorch.  \n",
        "\n",
        "Here we have:  \n",
        "\n",
        "1. 2 outer elements/batches/samples. The number of independent data pointsUnd\n",
        "1. Each outer element is a `3x3` matrix (`3 rows, 3 columns`)\n",
        "\n",
        "To make it easy to mentally visualize this tensor, you can imagine it as two stacked `3x3` matrices:\n",
        "\n",
        "```\n",
        "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "[[10, 11, 12], [13, 14, 15], [16, 17, 18]]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "bMQLTGeIM46Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Row Slice (Slice of the second row)**\n",
        "\n",
        "This expression extracts a slice of the tensor that consists of all elements in the second row of each 3x3 matrix within the tensor.  \n",
        "\n",
        "Using `tensor[:, 1, :]`\n",
        "\n",
        "1. First `:` means keep all elements along first dimension i.e. the outer dimension.  \n",
        "\n",
        "1. 1 means we want to select the second element along the second dimension i.e. the rows\n",
        "\n",
        "1. Last `:` means that we want all elements along the third dimension i.e. the columns"
      ],
      "metadata": {
        "id": "fIsmhVOTuM3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Row Slice (Slice of the second row)\n",
        "row_slice = tensor[:, 1, :]\n",
        "print(\"\\\\now Slice:\")\n",
        "print (row_slice)\n",
        "print (\"Row Slice Shape:\", row_slice.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY0chQy3uXBQ",
        "outputId": "e326541e-b7de-4d9f-ef81-89b8b060ca6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\now Slice:\n",
            "tensor([[ 4,  5,  6],\n",
            "        [13, 14, 15]])\n",
            "Row Slice Shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting tensor has two rows (corresponding to the two outer elements) and three columns (corresponding to the elements in the second row of each matrix)."
      ],
      "metadata": {
        "id": "gvd9XmTDOFb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Column Slice (Slice of the third column)**"
      ],
      "metadata": {
        "id": "yPSqTtguui-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column Slice (Slice of the third column)\n",
        "column_slice = tensor[:,:, 2]\n",
        "print (\"\\\\nColumn Slice:\")\n",
        "print(column_slice)\n",
        "print (\"Column Slice Shape:\", column_slice.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ99d0Y1uo8q",
        "outputId": "b116557f-17a2-44aa-923d-896daa7e5962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nColumn Slice:\n",
            "tensor([[ 3,  6,  9],\n",
            "        [12, 15, 18]])\n",
            "Column Slice Shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mixed Slice**"
      ],
      "metadata": {
        "id": "AoV5FGayusZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mixed Slice (Mixed slice of rows and columns)\n",
        "mixed_slice = tensor[:, 0:2, 1:3]\n",
        "print(\"\\\\nMixed Slice:\")\n",
        "print (mixed_slice)\n",
        "print(\"Mixed Slice Shape:\", mixed_slice.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gopWgt3fuzmB",
        "outputId": "69b4c88c-7903-4586-c7d0-0875b0714508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nMixed Slice:\n",
            "tensor([[[ 2,  3],\n",
            "         [ 5,  6]],\n",
            "\n",
            "        [[11, 12],\n",
            "         [14, 15]]])\n",
            "Mixed Slice Shape: torch.Size([2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reshaping and View in Tensors**"
      ],
      "metadata": {
        "id": "0wOw7cR9xCDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a contiguous 2D tensor\n",
        "tensor = torch.tensor([\n",
        "\t[1, 2, 3],\n",
        "\t[4, 5, 6]\n",
        "])\n",
        "# Reshape the tensor using view\n",
        "reshaped_tensor = tensor.view(3, 2)\n",
        "print(\"Original Tensor:\")\n",
        "print (tensor)\n",
        "print (\"\\\\nReshaped Tensor:\")\n",
        "print (reshaped_tensor)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDd5G7LOxI7E",
        "outputId": "44845764-ebee-4fde-8544-022af6a24c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\\nReshaped Tensor:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Create a non-contiguous 2D tensor using slicing\n",
        "tensor = torch. tensor([[1, 2, 3, 4, 5, 6]])\n",
        "sliced_tensor = tensor[:, :3]\n",
        "# Reshape the tensor using reshape\n",
        "reshaped_tensor = torch.reshape(sliced_tensor, (1, 3))\n",
        "print (\"Original Tensor:\")\n",
        "print (sliced_tensor)\n",
        "print(\"\\\\nReshaped Tensor:\")\n",
        "print (reshaped_tensor)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrDc9ZuvxZNQ",
        "outputId": "454a6145-bfc7-4d9c-c3ec-3a7d099cde8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            "tensor([[1, 2, 3]])\n",
            "\\nReshaped Tensor:\n",
            "tensor([[1, 2, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The `-1` trick in `view()`.**\n",
        "Automatic inference of dimensions.\n"
      ],
      "metadata": {
        "id": "zRQJsMSZxiFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Create a tensor with size (2, 4)\n",
        "tensor = torch. tensor([\n",
        "\t[1, 2, 3, 4],\n",
        "\t[5, 6, 7, 8]\n",
        "])\n",
        "# Reshape the tensor using view and -1 trick\n",
        "reshaped_tensor = tensor.view(-1, 2)\n",
        "print(\"Original Tensor:\")\n",
        "print (tensor)\n",
        "print (\"\\\\nReshaped Tensor:\")\n",
        "print (reshaped_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAfkbskgxnc0",
        "outputId": "67e0e726-ad4c-4559-966f-aa90dc9fecef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "\\nReshaped Tensor:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Breakdown:**\n",
        "\n",
        "1. `tensor`: This refers to the original tensor you want to reshape.\n",
        "1. `view(-1, 2)`: This specifies the new shape:\n",
        "  - `-1`: Indicates that the first dimension should be inferred automatically.\n",
        "  - `2`: Specifies that the second dimension should be 2.  \n",
        "\n",
        "PyTorch calculates the total number of elements in the original tensor.\n",
        "It then determines the appropriate value for the first dimension `(-1)` based on the total number of elements and the desired second dimension of 2.\n",
        "The tensor is then reshaped accordingly, preserving the total number of elements."
      ],
      "metadata": {
        "id": "opNxfFdTIC6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a= torch.ones(2,3,4)\n",
        "b= a.view(1,4,-1)\n",
        "print(b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62ZcRavgYlZe",
        "outputId": "84ae3e11-0402-4a58-d8be-8bf7fed5e654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Gradient calculation with Tensors**"
      ],
      "metadata": {
        "id": "NOSt_Fk7zKJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Enable gradient tracking\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "# Perform operations on the tensor\n",
        "z = x ** 2 + 1\n",
        "\n",
        "# Compute gradients\n",
        "z.backward()\n",
        "\n",
        "# Access the computed gradients\n",
        "x_grad = x.grad\n",
        "\n",
        "print(x_grad)"
      ],
      "metadata": {
        "id": "FySgkdiAzNXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "216b981a-a1a6-47a0-8433-6ca87cbed26c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Detaching and `no_grad()`**.\n",
        "\n",
        "`detach()`  \n",
        "\n",
        "- **Purpose:** Creates a new tensor that shares the same storage as the original tensor but is detached from its computational graph.  \n",
        "\n",
        "- **Effect:** When you call `detach()` on a tensor, it effectively breaks the connection between that tensor and the computational graph. This means that subsequent operations on the detached tensor will not contribute to the gradient calculation."
      ],
      "metadata": {
        "id": "dZPM53mUzZWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(3, 3, requires_grad=True)\n",
        "y = x.detach()\n",
        "\n",
        "# Operations on y will not affect the gradient of x\n",
        "z = y * 2\n",
        "\n",
        "try:\n",
        "    z.backward()  # This will raise an error because y is detached\n",
        "except RuntimeError as e:\n",
        "    print(\"Error:\", e)\n",
        "print(f'Gradients of x: {x.grad}')  # Output: None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZCoUsC5PvJQ",
        "outputId": "788854fa-948b-408a-a4db-ee0a6d3d924b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: element 0 of tensors does not require grad and does not have a grad_fn\n",
            "Gradients of x: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`no_grad()`\n",
        "- **Purpose:** Creates a context manager that temporarily disables automatic gradient calculation for all operations within its scope.\n",
        "- **Effect:** When you use the `no_grad()` context manager, any operations performed within its block will not contribute to the gradient calculation. This can be useful for performance optimization or when you want to evaluate a model without updating its parameters.\n"
      ],
      "metadata": {
        "id": "lpiqwDXhVH4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor with tracking enabled\n",
        "x = torch.tensor([3.0], requires_grad=True)\n",
        "\n",
        "# Perform operations on the tensor\n",
        "y = x**2 + 2*x + 1\n",
        "print(f'y: {y}')\n",
        "\n",
        "# Stop tracking gradients using detach()\n",
        "# Detach the tensor from the computational graph\n",
        "z = y.detach()\n",
        "print(f'z: {z}')\n",
        "\n",
        "\n",
        "# Perform further operations without tracking\n",
        "with torch.no_grad() :\n",
        "  w = z * 2\n",
        "print(f'w: {w}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWx3fNy2zgYV",
        "outputId": "619f3703-f996-4964-d054-2368866c276b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y: tensor([16.], grad_fn=<AddBackward0>)\n",
            "z: tensor([16.])\n",
            "w: tensor([32.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    x = torch.randn(3, 3, requires_grad=True)\n",
        "    y = x * 2\n",
        "    z = y.sum()\n",
        "\n",
        "# Operations on x, y, and z within the context manager did not contribute to gradients\n",
        "print(f'x: {x}')\n",
        "print(f'y: {y}')\n",
        "print(f'z: {z}', end='\\n\\n')\n",
        "\n",
        "print(f'Gradients of x: {x.grad}')  # Output: None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJDHEsoURCmS",
        "outputId": "dd1a04d7-08c8-4748-c5f5-5904d6aa38c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([[ 1.1375,  1.1863, -0.9315],\n",
            "        [-0.1975, -0.3978, -0.5008],\n",
            "        [-0.4273, -1.4600,  0.1484]], requires_grad=True)\n",
            "y: tensor([[ 2.2750,  2.3726, -1.8631],\n",
            "        [-0.3950, -0.7955, -1.0017],\n",
            "        [-0.8545, -2.9199,  0.2967]])\n",
            "z: -2.885369300842285\n",
            "\n",
            "Gradients of x: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors in Neural Net\n",
        "### **Weighted Sum Computation**\n",
        "The mathematical operation for calculating the weighted sum in a neural network is essentially a matrix multiplication followed by vector addition."
      ],
      "metadata": {
        "id": "IyG92dqnv7wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define input, weights, and bias tensors\n",
        "input_tensor = torch.randn(4, 3)  # 4 samples, 3 features\n",
        "weights_tensor = torch.randn(3, 5)  # 3 input features, 5 output features\n",
        "bias_tensor = torch.randn(5)  # 5 output features\n",
        "\n",
        "# Calculate weighted sum\n",
        "weighted_sum = torch.matmul(input_tensor, weights_tensor) + bias_tensor\n",
        "\n",
        "# Apply activation function (e.g., ReLU)\n",
        "output_tensor = torch.relu(weighted_sum)\n",
        "\n",
        "print(output_tensor.shape)  # Output: torch.Size([4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFavJ6ZgXTFO",
        "outputId": "e7a0c311-5404-4508-c951-d3d3f93c8fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Input tensor:** A `4x3` tensor representing 4 samples with 3 features each.\n",
        "1. **Weights tensor:** A `3x5` tensor representing the weights for a fully connected layer with 3 input neurons and 5 output neurons.\n",
        "1. **Bias tensor:** A 1D tensor with 5 elements, representing the biases for each output neuron.\n",
        "1. **Weighted sum:** The input tensor is multiplied by the weights tensor, and the bias tensor is added to the result.\n",
        "1. **Output tensor:** The weighted sum is passed through the ReLU activation function to produce the final output.\n",
        "The output tensor will have a shape of (4, 5), indicating that for each of the 4 input samples, the neural network produces 5 output values."
      ],
      "metadata": {
        "id": "G8xKjMaOXfTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Numpy's Efficiency and Advantages over Lists**"
      ],
      "metadata": {
        "id": "zn3kUWzlOuDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numpy's superior performance compared to Python lists stems from several key factors:\n",
        "\n",
        "1. **Memory Efficiency:**\n",
        "   - Numpy arrays are stored in **contiguous memory blocks**, allowing for efficient access and manipulation.\n",
        "   - Python lists, on the other hand, store elements as pointers to objects, leading to overhead in memory allocation and retrieval.\n",
        "\n",
        "2. **Vectorized Operations:**\n",
        "   - Numpy provides vectorized operations that perform operations on entire arrays at once, avoiding the need for explicit loops.\n",
        "   - This significantly improves performance, especially for large datasets.\n",
        "\n",
        "3. **C/C++ Implementation:**\n",
        "   - Numpy is implemented in C and Fortran, which are much faster than Python.\n",
        "   - This allows for efficient execution of numerical computations.\n",
        "\n",
        "4. **Optimized Algorithms:**\n",
        "   - Numpy leverages highly optimized algorithms for common mathematical operations, further enhancing performance.\n",
        "\n",
        "5. **Broadcasting:**\n",
        "   - Numpy's broadcasting mechanism allows for automatic shape inference and element-wise operations between arrays of different shapes.\n",
        "   - This simplifies code and improves performance."
      ],
      "metadata": {
        "id": "gxkynz4ZXAUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a Python list\n",
        "python_list = list(range(1000000))\n",
        "\n",
        "# Create a Numpy array\n",
        "numpy_array = np.array(python_list)"
      ],
      "metadata": {
        "id": "E6CDt0kZJv5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiplication_for_loop(list):\n",
        "    result = []\n",
        "    for item in list:\n",
        "        result.append(item * 2)\n",
        "    return result"
      ],
      "metadata": {
        "id": "S_CwnITtRqWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise multiplication in Python list using for loop\n",
        "%timeit result_list = multiplication_for_loop(python_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCsPz99LR2uR",
        "outputId": "54466029-8303-4ff5-8e2b-37c8d3a76af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163 ms ± 52 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise multiplication in Python list with list comprehension\n",
        "%timeit result_list = [x * 2 for x in python_list]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1b2H3cXJ0S4",
        "outputId": "dbae5d5f-3f98-4a41-baae-17318dfa9549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52.1 ms ± 1.25 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise multiplication in Numpy array\n",
        "%timeit result_array = numpy_array * 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx3QHiqrJyRH",
        "outputId": "cb1a233a-ae5d-4987-9c5f-33c9bd532e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.33 ms ± 112 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    }
  ]
}